{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Class 1 AD: WM\n"
      ],
      "metadata": {
        "id": "T5cKQyMO1W8L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HIHbGz7t7zt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/WM/AD\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [34.4, 34.1, 34.2, 33.6, 30, 29.7, 29.6, 29.3],\n",
        "    [36, 35.4, 35.1, 35.2, 30.5, 34.2, 31.7, 32.8],\n",
        "    [33.2, 33.1, 31.4, 30.9, 31.5, 31.1, 31.7, 30.6],\n",
        "    [31.4, 30.7, 30.6, 29.9, 29.4, 29.8, 30.5, 29.9],\n",
        "    [29.2, 28.9, 28.6, 28.4, 30.5, 20.3, 30.1, 29.5],\n",
        "    [35, 35.5, 35.1, 34.4, 32.5, 32.6, 32.2, 31.5],\n",
        "    [30.9, 30.6, 31.2, 32, 33.3, 33.3, 33.5, 32.5],\n",
        "    [25.9, 28.2, 24.8, 25.7, 35.9, 35.2, 35, 34.4]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"WM_Volume_Relative_class1_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class 2 CN: WM"
      ],
      "metadata": {
        "id": "tKcRLqRf1_ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/WM/CN\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "32.9, 32.8, 33.1, 32.4, 32.2, 33.4, 35.6, 33.8, 33.6, 34.2,\n",
        "31.5, 30.5, 31.1, 30.8, 30.5, 31.1, 30.6, 30.5, 30.3, 29.9,\n",
        "31.8, 31.4, 31.3, 31, 31.3, 33.4, 33.1, 33.2, 33.9, 33.1,\n",
        "33.2, 31.8, 30.8, 31.2, 30.2, 33.3, 33.6, 33, 33, 32.9,\n",
        "31.6, 31.5, 31.6, 31.1, 31.2, 34.5, 34.6, 34.9, 34.7, 34.5,\n",
        "33.4, 33.2, 33.1, 33.5, 33.1, 33.8, 34.1, 34.2, 34.4, 34.2,\n",
        "31, 31.4, 30.8, 31.2, 31.1, 30.5, 31.1, 30.9, 31.3, 30.7,\n",
        "31.5, 31.7, 31.3, 31.1, 31.4, 33.3, 34.5, 34.3, 34.6, 34.2,\n",
        "35.9, 35.5, 35.6, 35.4, 34.7, 34.2, 34.5, 33.2, 33.7, 33.2,\n",
        "32.8, 33, 33.1, 31.9, 32, 32.7, 33.2, 33.3, 33.3, 33.3,\n",
        "31, 31.1, 30.9, 30.3, 31.2, 28.5, 29.1, 30.3, 30.2, 29.7,\n",
        "36.3, 36.3, 36.6, 35.6, 35.6, 32.6, 32.1, 32.3, 32, 31.9\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"WM_Volume_Relative_class2_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "UjsjqJluxE6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class 3 EMCI: WM"
      ],
      "metadata": {
        "id": "ZBmPw2nE1NiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/WM/EMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [33.9, 34.9, 33.2, 34, 34, 34.5, 33.8, 34.7, 34.5, 35.6,\n",
        "    33.1, 32.1, 32.1, 32.3, 34.2, 34, 34.1, 34.4, 35.3, 34.4,\n",
        "    34.8, 34.7, 34.9, 34.8, 34.8, 32.2, 33, 32.8, 32.7, 32.5,\n",
        "    32.7, 32.8, 35.5, 35.8, 35.4, 35.3, 36, 35.4, 33.9, 33.9,\n",
        "    33.1, 32.8, 32.4, 32.5, 34, 32, 32.2, 32.4, 32.2, 32.1,\n",
        "    32, 36.9, 37, 37, 37, 37.5, 36.8]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"WM_Volume_Relative_class3_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")\n"
      ],
      "metadata": {
        "id": "f1CYC2_E27XP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Class 4 LMCI: WM"
      ],
      "metadata": {
        "id": "hdoql5493P9U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/WM/LMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [24.9, 28.6, 29, 28.6, 28.3, 27.9, 27.7, 31.9, 31.3, 30.8,\n",
        "    24.7, 30.1, 30.1, 30.1, 30.2, 30, 29.7, 31.8, 31.2, 30.8,\n",
        "    30.8, 30.4, 29.8, 29.8, 29.6, 29.5, 29.6, 29.1, 30.7, 31.1,\n",
        "    31, 30.6, 30.8, 30.7, 31.5, 30.2, 31.8, 31.7, 30.5, 31.1,\n",
        "    29.2, 30.1, 29.4, 28.6, 29.5, 29.4, 29.4, 29.1, 29, 30.7,\n",
        "    29, 29.3, 28.9, 29, 29.1, 29]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"WM_Volume_Relative_class4_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "LF4B7Abr3h1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Class 1 : GM AD"
      ],
      "metadata": {
        "id": "05qCBZNC6lJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/GM/AD\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [44, 43.8, 44.2, 42.9, 39.8, 29.7, 38.8, 38.2, 40.4, 39.5,\n",
        "    39.5, 38.5, 38.3, 37.3, 38.4, 37.8, 38.2, 38.4, 38.1, 35.1,\n",
        "    42.3, 41.8, 40.8, 40.8, 41.2, 39.7, 40.2, 39.6, 40.2, 40.2,\n",
        "    39.2, 39.6, 39.7, 39.4, 39.9, 39.2, 39.8, 39.9, 38.9, 28.2,\n",
        "    42.4, 42.4, 42.5, 41.4, 43, 42.2, 42.4, 41.1, 39.5, 38.7,\n",
        "    39.2, 36.8, 41.3, 41.3, 41.4, 39.7, 36, 35.7, 36, 36.4,\n",
        "    45.8, 46.4, 44.9, 43.6, 43.8, 43.1, 43.5, 42.1, 35.7, 35.3,\n",
        "    35.8, 35.2]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"GM_Volume_Relative_class1_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "7bQTsL-M6sgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 2: GM CN"
      ],
      "metadata": {
        "id": "vF-Ks4LF7Owd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/GM/CN\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [42.4, 42.5, 43, 42, 42.5, 38.9, 39.9, 38.7, 40.2, 37.8,\n",
        "    43.1, 41.5, 42.4, 42.1, 42.2, 35.4, 37.8, 38.1, 36.5, 37.3,\n",
        "    45.3, 45.2, 43.9, 44.2, 43.5, 44.2, 43.7, 43.6, 42.9, 44.1,\n",
        "    42.7, 44.2, 43, 42.6, 43.2, 43.9, 43.5, 43.5, 43.3, 43.3,\n",
        "    42.3, 41.8, 42.7, 41.3, 42.4, 43.4, 43.3, 41.9, 43, 42.4,\n",
        "    43.3, 42.9, 42.7, 42.6, 42.7, 44.5, 43.6, 44.2, 44.7, 44,\n",
        "    44.2, 43.5, 43.7, 44, 42.9, 42.5, 42.2, 43.1, 43.2, 43.3,\n",
        "    43, 43.4, 42.7, 43, 42.8, 40.3, 41.8, 41.2, 41.5, 41.4,\n",
        "    40.7, 40.5, 40.7, 40.4, 39, 43.6, 43.5, 42.8, 43.1, 42.8,\n",
        "    43.2, 43.1, 43, 42.4, 42.9, 45.5, 45.5, 45.7, 45, 44.9,\n",
        "    43.8, 44.2, 43.8, 42.7, 42.2, 39.7, 39.8, 40.9, 40.9, 41.9,\n",
        "    46.9, 46.6, 46.9, 44.1, 44.8, 43.1, 42.6, 42.4, 43.3, 42.7]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"GM_Volume_Relative_class2_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "z44cyaOx7M7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 3: GM EMCI"
      ],
      "metadata": {
        "id": "5Uqqneqz7d3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/GM/EMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [37.5, 38.5, 36, 37.3, 34.9, 40.1, 40, 38.7, 38.3, 39,\n",
        "    38.9, 44.1, 45.5, 45.5, 40.3, 40.2, 40.7, 39.4, 38.9, 39.1,\n",
        "    38.9, 39.6, 40.2, 39.7, 38.7, 42.1, 37.4, 38.2, 37.8, 38.2,\n",
        "    38.5, 37.6, 40.5, 40.6, 40.4, 40.5, 38.6, 40, 42.1, 40.7,\n",
        "    41.9, 41, 40.8, 42.2, 39.8, 39.2, 37.2, 43.6, 43.2, 42.5,\n",
        "    42.3, 42.8, 42.2, 42.4, 42.7, 41.9, 41.4]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"GM_Volume_Relative_class3_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "eedCwt8f7kat",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 4: GM LMCI"
      ],
      "metadata": {
        "id": "YrgKwBBP7tN6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/GM/LMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [38, 41.9, 40.5, 41.2, 41, 40.3, 39.7, 44.6, 45, 43.9,\n",
        "    39.8, 41, 41, 41.3, 41, 40.7, 40.9, 42.5, 41, 40.9,\n",
        "    40.6, 40.1, 41.9, 40.8, 41.2, 40.9, 41.4, 40.7, 43.2, 43.5,\n",
        "    43.2, 42.9, 43.1, 42.8, 43.5, 40.4, 42.5, 42.9, 38.4, 39.5,\n",
        "    36.2, 37.3, 37.2, 35.6, 40.3, 39.8, 40.1, 39.7, 39.4, 37.4,\n",
        "    37.9, 39, 37.2, 37, 37.5, 38.2]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"GM_Volume_Relative_class4_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "X-g7hSym7zX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 1: CSF AD"
      ],
      "metadata": {
        "id": "Xmbz0_zO8c4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/CSF/AD\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [21.5, 22.1, 21.7, 23.5, 30.2, 31.3, 31.5, 32.5, 23.6, 25.1,\n",
        "    25.4, 26.4, 31.2, 28.5, 29.9, 29.4, 28.6, 28.5, 30.5, 33.9,\n",
        "    26.2, 27.1, 27.4, 28.6, 27.4, 29.6, 29.1, 30.4, 30.4, 30,\n",
        "    30.4, 30.6, 31.1, 31.8, 31.5, 32.5, 29.7, 29.7, 31, 32.2,\n",
        "    22.5, 22.1, 22.4, 24.2, 24.5, 25.2, 25.5, 27.4, 29.5, 30.6,\n",
        "    29.6, 31.3, 25.4, 25.4, 25.1, 27.8, 38.1, 36.1, 39.2, 37.9,\n",
        "    18.3, 18.4, 20.1, 22, 19.1, 20, 18.9, 21, 33.6, 34.5,\n",
        "    33.9, 34.7]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"CSF_Volume_class1_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "JtWD_ERa8h-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 2: CSF CN"
      ],
      "metadata": {
        "id": "b1XuYEbf9IDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/CSF/CN\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [24.7, 24.7, 23.9, 25.6, 25.3, 27.8, 24.5, 27.6, 26.2, 28.1,\n",
        "    25.4, 28, 26.5, 27.1, 27.3, 33.5, 31.6, 31.3, 33.2, 32.8,\n",
        "    22.9, 23.5, 24.8, 24.8, 25.1, 22.4, 23.1, 23.2, 23.2, 22.8,\n",
        "    25, 24, 26.2, 26.2, 26.5, 22.8, 22.8, 23.5, 23.7, 23.8,\n",
        "    26.1, 26.6, 25.7, 27.5, 26.4, 22.1, 22.2, 23.1, 22.9, 23,\n",
        "    23.3, 23.1, 23.5, 22.8, 23.3, 21.7, 21.5, 21.4, 21.8, 21.6,\n",
        "    24, 24, 24.8, 23.5, 24.5, 27, 27.5, 27, 27.2, 26.8,\n",
        "    25.5, 24.6, 25.2, 24.3, 25.1, 26.4, 23.7, 24.5, 23.9, 24.4,\n",
        "    23.4, 23.9, 23.7, 24.2, 26.3, 22.2, 22.1, 24, 23.2, 24,\n",
        "    24, 23.8, 23.9, 25.8, 25, 21.8, 21.3, 21, 21.7, 21.8,\n",
        "    25.2, 24.7, 25.2, 26.9, 26.5, 31.7, 31.1, 38.7, 28.9, 28.3,\n",
        "    16.8, 17.1, 16.4, 20.3, 19.6, 24.3, 25.3, 25.3, 24.7, 25.5]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"CSF_Volume_class2_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "9-ydNT5J9KPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 3: CSF EMCI"
      ],
      "metadata": {
        "id": "-MPvkWl99SY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/CSF/EMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [28.6, 26.6, 30.9, 28.7, 31.1, 25.3, 26.2, 26.6, 27.2, 25.5,\n",
        "    28, 23.8, 22.3, 22.1, 25.5, 25.8, 25.2, 26.2, 25.8, 26.5,\n",
        "    26.3, 25.7, 24.9, 25.5, 26.6, 25.7, 29.6, 28.5, 30, 29.6,\n",
        "    29.5, 29.2, 24, 23.6, 24.2, 24.2, 25.3, 24.5, 24, 25.4,\n",
        "    25.1, 26.2, 26.8, 25.3, 26.2, 28.8, 30.6, 24, 24.7, 25.4,\n",
        "    25.8, 20.3, 20.8, 20.6, 20.2, 20.6, 21.8]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"CSF_Volume_class3_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "WPXAEwG29X1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 4: CSF LMCI"
      ],
      "metadata": {
        "id": "jB9tl-yL-FKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/CSF/LMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [27.1, 29.5, 30.5, 30.2, 30.6, 31.8, 32.6, 23.5, 23.7, 25.3,\n",
        "    25.5, 29, 28.9, 28.6, 28.8, 29.3, 29.5, 25.7, 27.8, 28.3,\n",
        "    25.5, 29.5, 28.3, 29.4, 29.2, 29.6, 29, 30.2, 26, 25.4,\n",
        "    25.8, 26.5, 26.1, 26.4, 28.8, 29.4, 25.7, 25.3, 31.1, 29.5,\n",
        "    34.6, 32.6, 33.4, 35.8, 30.2, 30.8, 30.6, 31.2, 31.6, 31.9,\n",
        "    33, 31.7, 33.9, 34, 33.4, 32.8]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"CSF_Volume_class4_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "du_SqT8Y-H5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 1: CTh AD"
      ],
      "metadata": {
        "id": "U-suwOTB-app"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/Cortical Thickness/AD\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [2.42, 2.41, 2.41, 2.38, 2.28, 2.23, 2.20, 2.18, 2.18, 2.19,\n",
        "    2.16, 2.13, 2.19, 2.09, 2.15, 2.08, 2.05, 2.06, 2.10, 1.99,\n",
        "    2.33, 2.31, 2.24, 2.24, 2.36, 2.32, 2.32, 2.32, 2.27, 2.28,\n",
        "    2.21, 2.23, 2.34, 2.30, 2.37, 2.36, 2.31, 2.31, 2.29, 2.24,\n",
        "    2.35, 2.33, 2.33, 2.29, 2.44, 2.41, 2.42, 2.37, 2.32, 2.31,\n",
        "    2.25, 2.12, 2.28, 2.28, 2.25, 2.17, 2.19, 2.11, 2.19, 2.14,\n",
        "    2.48, 2.52, 2.50, 2.45, 2.47, 2.46, 2.44, 2.42, 2.38, 2.36,\n",
        "    2.46, 2.35]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"Cortical_Thickness_Volume_class1_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "iviNC_SZ-grU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 2: CTh CN"
      ],
      "metadata": {
        "id": "uquewCIB--b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/Cortical Thickness/CN\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [2.47, 2.47, 2.48, 2.46, 2.48, 2.36, 2.32, 2.30, 2.36, 2.22,\n",
        "    2.45, 2.42, 2.44, 2.42, 2.43, 2.31, 2.44, 2.46, 2.41, 2.41,\n",
        "    2.36, 2.37, 2.35, 2.35, 2.32, 2.44, 2.44, 2.44, 2.38, 2.44,\n",
        "    2.43, 2.48, 2.49, 2.42, 2.48, 2.42, 2.40, 2.42, 2.40, 2.38,\n",
        "    2.48, 2.43, 2.46, 2.42, 2.46, 2.48, 2.46, 2.41, 2.41, 2.39,\n",
        "    2.48, 2.43, 2.44, 2.44, 2.47, 2.43, 2.40, 2.42, 2.44, 2.43,\n",
        "    2.46, 2.48, 2.46, 2.48, 2.49, 2.45, 2.42, 2.44, 2.43, 2.45,\n",
        "    2.42, 2.47, 2.44, 2.46, 2.47, 2.27, 2.32, 2.29, 2.29, 2.26,\n",
        "    2.34, 2.36, 2.34, 2.33, 2.30, 2.43, 2.42, 2.45, 2.43, 2.45,\n",
        "    2.42, 2.41, 2.39, 2.41, 2.43, 2.50, 2.47, 2.50, 2.48, 2.45,\n",
        "    2.33, 2.34, 2.34, 2.30, 2.25, 2.51, 2.49, 2.43, 2.43, 2.49,\n",
        "    2.34, 2.33, 2.31, 2.30, 2.28, 2.38, 2.39, 2.36, 2.40, 2.37,\n",
        "    2.24, 2.21, 2.22, 2.18, 2.17, 2.12, 2.36, 2.40, 2.32, 2.30,\n",
        "    2.25, 2.36, 2.38, 2.30, 2.35, 2.33, 2.29, 2.37, 2.29, 2.33,\n",
        "    2.36, 2.33, 2.34, 2.26, 2.08, 2.10, 2.07, 2.02, 1.95, 1.98,\n",
        "    2.35, 2.38, 2.36, 2.39, 2.37, 2.28, 2.46, 2.47, 2.48, 2.45,\n",
        "    2.45, 2.45, 2.50, 2.51, 2.48, 2.45, 2.45, 2.41, 2.43, 2.37,\n",
        "    2.39, 2.36, 2.39, 2.36, 2.37, 2.34, 2.35, 2.33, 2.36, 2.34,\n",
        "    2.49, 2.49, 2.49, 2.49, 2.51, 2.48, 2.31, 2.32, 2.28, 2.32,\n",
        "    2.23, 2.31, 2.32, 2.24, 2.35, 2.30, 2.20, 2.35, 2.14, 2.24,\n",
        "    2.25, 2.31, 2.13, 2.43, 2.41, 2.41, 2.45, 2.40, 2.40, 2.28,\n",
        "    2.29, 2.22, 2.23, 2.22, 2.18, 2.29, 2.25, 2.26, 2.24, 2.24,\n",
        "    2.07, 2.34, 2.34, 2.25, 2.24, 2.26, 2.26, 2.52, 2.51, 2.51,\n",
        "    2.52, 2.41, 2.46]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"Cortical_Thickness_Volume_class2_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "5MlRCq1U_CTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 3: CTh EMCI"
      ],
      "metadata": {
        "id": "zwjto2eS_ZXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/Cortical Thickness/EMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [2.24, 2.22, 2.18, 2.17, 2.12, 2.36, 2.40, 2.32, 2.30, 2.25,\n",
        "    2.36, 2.29, 2.36, 2.33, 2.08, 2.10, 2.07, 2.02, 1.95, 1.98,\n",
        "    2.35, 2.36, 2.39, 2.37, 2.28, 2.50, 2.37, 2.34, 2.35, 2.33,\n",
        "    2.36, 2.34, 2.31, 2.32, 2.28, 2.32, 2.23, 2.31, 2.32, 2.24,\n",
        "    2.35, 2.30, 2.20, 2.35, 2.14, 2.25, 2.13, 2.43, 2.41, 2.40,\n",
        "    2.40, 2.52, 2.51, 2.51, 2.52, 2.41, 2.46]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"Cortical_Thickness_Volume_class3_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "1J8tQqVU_c98"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CLASS 4: CTh LMCI"
      ],
      "metadata": {
        "id": "9bWxLKq3_xZY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Create output folder in Google Drive\n",
        "output_folder = \"/content/drive/MyDrive/AD paper code/Cortical Thickness/LMCI\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "# Functions for Image Augmentation\n",
        "def quantize_image(image, bits):\n",
        "    levels = 2 ** bits\n",
        "    factor = 256 / levels\n",
        "    quantized_image = (image // factor) * factor\n",
        "    return quantized_image\n",
        "\n",
        "def random_rotation(image):\n",
        "    angle = random.randint(0, 360)\n",
        "    return np.array(Image.fromarray(image).rotate(angle))\n",
        "\n",
        "def random_flip(image):\n",
        "    if random.choice([True, False]):\n",
        "        image = np.fliplr(image)\n",
        "    if random.choice([True, False]):\n",
        "        image = np.flipud(image)\n",
        "    return image\n",
        "\n",
        "def random_noise(image):\n",
        "    noise = np.random.normal(0, 25, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    noisy_image = np.clip(noisy_image, 0, 255)\n",
        "    return noisy_image.astype(np.uint8)\n",
        "\n",
        "def random_brightness(image):\n",
        "    factor = random.uniform(0.5, 1.5)\n",
        "    return np.clip(image * factor, 0, 255).astype(np.uint8)\n",
        "\n",
        "# Create Base Image from Data\n",
        "data = [\n",
        "    [2.21, 2.38, 2.30, 2.35, 2.33, 2.29, 2.37, 2.33, 2.34, 2.26,\n",
        "    2.38, 2.46, 2.47, 2.48, 2.45, 2.45, 2.45, 2.51, 2.48, 2.45,\n",
        "    2.45, 2.41, 2.43, 2.37, 2.39, 2.36, 2.39, 2.36, 2.49, 2.49,\n",
        "    2.49, 2.49, 2.51, 2.48, 2.24, 2.31, 2.41, 2.45, 2.28, 2.29,\n",
        "    2.22, 2.23, 2.22, 2.18, 2.29, 2.25, 2.26, 2.24, 2.24, 2.07,\n",
        "    2.34, 2.34, 2.25, 2.24, 2.26, 2.26]\n",
        "]\n",
        "\n",
        "data_matrix = np.array(data)\n",
        "image = np.array(data_matrix, dtype=np.uint8)\n",
        "\n",
        "\n",
        "num_images = 500\n",
        "\n",
        "\n",
        "for i in range(num_images):\n",
        "    bits = np.random.choice([2, 3, 4, 8, 16])\n",
        "    quantized_image = quantize_image(image, bits)\n",
        "    augmented_image = random_rotation(quantized_image)\n",
        "    augmented_image = random_flip(augmented_image)\n",
        "    augmented_image = random_noise(augmented_image)\n",
        "    augmented_image = random_brightness(augmented_image)\n",
        "\n",
        "    plt.figure(figsize=(5, 4))\n",
        "    plt.imshow(augmented_image, cmap='coolwarm', interpolation='nearest')\n",
        "    plt.title(f\"Cortical_Thickness_Volume_class4_Image - Image {i+1}\")\n",
        "    plt.axis('off')\n",
        "\n",
        "\n",
        "    save_path = os.path.join(output_folder, f\"wm_image_{i+1}.png\")\n",
        "    plt.savefig(save_path, bbox_inches='tight', pad_inches=0.1)\n",
        "    plt.close()  # Close the figure to save memory\n",
        "\n",
        "print(f\"✅ All {num_images} images saved in: {output_folder}\")"
      ],
      "metadata": {
        "id": "yE2v-7IB_1Ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CNN"
      ],
      "metadata": {
        "id": "1sH1q9vx70h6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to load data\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_mapping = {}\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Path {data_dir} does not exist.\")\n",
        "        return None, None, None\n",
        "\n",
        "    class_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])\n",
        "\n",
        "    if not class_folders:\n",
        "        print(f\"No class folders found in {data_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    for idx, class_name in enumerate(class_folders):\n",
        "        class_mapping[class_name] = idx\n",
        "\n",
        "    print(f\"Found classes in {data_dir}: {class_mapping}\")\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img = load_img(img_path, target_size=(128, 128))\n",
        "                img_array = img_to_array(img) / 255.0\n",
        "\n",
        "                images.append(img_array)\n",
        "                labels.append(class_mapping[class_name])\n",
        "\n",
        "    return np.array(images), np.array(labels), class_mapping\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(data_dir, regularization_type=None):\n",
        "    images, labels, class_mapping = load_data(data_dir)\n",
        "\n",
        "    if images is None or labels is None or len(images) == 0:\n",
        "        print(f\"Skipping training for {data_dir} (No data found!)\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    regularizer = None\n",
        "    if regularization_type == 'L1':\n",
        "        regularizer = regularizers.l1(0.01)\n",
        "    elif regularization_type == 'L2':\n",
        "        regularizer = regularizers.l2(0.01)\n",
        "    elif regularization_type == 'L1_L2':\n",
        "        regularizer = regularizers.l1_l2(l1=0.01, l2=0.01)\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3), kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(len(class_mapping), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Evaluate the model and plot confusion matrix\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "    class_names = [class_name for class_name, idx in sorted(class_mapping.items(), key=lambda x: x[1])]\n",
        "    plot_confusion_matrix(y_test, y_pred, class_names)\n",
        "\n",
        "    return model, X_test, y_test, history, class_mapping\n",
        "\n",
        "# Paths to your dataset\n",
        "data_dirs = {\n",
        "    \"Thickness\": \"/content/drive/MyDrive/wm/drive/Thickness\",\n",
        "    \"CSF\": \"/content/drive/MyDrive/wm/drive/CSF\",\n",
        "    \"GM\": \"/content/drive/MyDrive/wm/drive/GM\",\n",
        "    \"WM\": \"/content/drive/MyDrive/wm/drive/WM\",\n",
        "}\n",
        "\n",
        "regularization_type = 'L2'\n",
        "\n",
        "# Store models, test data, histories, and class mappings for each dataset\n",
        "models = {}\n",
        "test_data = {}\n",
        "histories = {}\n",
        "class_mappings = {}\n",
        "\n",
        "for title, path in data_dirs.items():\n",
        "    if os.path.exists(path):\n",
        "        model, X_test, y_test, history, class_mapping = train_model(path, regularization_type)\n",
        "        if model is not None:\n",
        "            models[title] = model\n",
        "            test_data[title] = (X_test, y_test)\n",
        "            histories[title] = history\n",
        "            class_mappings[title] = class_mapping\n",
        "    else:\n",
        "        print(f\"Skipping {title}: Path does not exist.\")\n",
        "\n",
        "# Plot training and validation metrics as before\n"
      ],
      "metadata": {
        "id": "2ZQpQ74P-eML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FCN"
      ],
      "metadata": {
        "id": "-NAUSHo_6OKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras import regularizers\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "##################################\n",
        "########## Load Data #############\n",
        "##################################\n",
        "\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_mapping = {}\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Path {data_dir} does not exist.\")\n",
        "        return None, None\n",
        "\n",
        "    class_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])\n",
        "\n",
        "    if not class_folders:\n",
        "        print(f\"No class folders found in {data_dir}\")\n",
        "        return None, None\n",
        "\n",
        "    for idx, class_name in enumerate(class_folders):\n",
        "        class_mapping[class_name] = idx\n",
        "\n",
        "    print(f\"Found classes in {data_dir}: {class_mapping}\")\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img = load_img(img_path, target_size=(128, 128))\n",
        "                img_array = img_to_array(img) / 255.0\n",
        "\n",
        "                images.append(img_array)\n",
        "                labels.append(class_mapping[class_name])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Custom callback (optional for performance reporting)\n",
        "class PerformanceReportCallback(Callback):\n",
        "    def __init__(self, class_mapping, val_data):\n",
        "        super().__init__()\n",
        "        self.class_mapping = class_mapping\n",
        "        self.val_data = val_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Custom logic for performance reporting (if needed)\n",
        "        pass\n",
        "\n",
        "##################################\n",
        "########## Training ##############\n",
        "##################################\n",
        "def train_model(data_dir, regularization_type=None):\n",
        "    images, labels = load_data(data_dir)\n",
        "\n",
        "    if images is None or labels is None or len(images) == 0:\n",
        "        print(f\"Skipping training for {data_dir} (No data found!)\")\n",
        "        return None\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    regularizer = None\n",
        "    if regularization_type == 'L1':\n",
        "        regularizer = regularizers.l1(0.01)\n",
        "    elif regularization_type == 'L2':\n",
        "        regularizer = regularizers.l2(0.01)\n",
        "    elif regularization_type == 'L1_L2':\n",
        "        regularizer = regularizers.l1_l2(l1=0.01, l2=0.01)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3), kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.Dense(len(set(labels)), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Evaluate the model and plot confusion matrix\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "    class_names = [class_name for class_name, idx in sorted({class_name: idx for idx, class_name in enumerate(set(labels))}.items(), key=lambda x: x[1])]\n",
        "    plot_confusion_matrix(y_test, y_pred, class_names)\n",
        "\n",
        "    return history\n",
        "\n",
        "# Paths to your dataset\n",
        "data_dirs = {\n",
        "    \"GM\": \"/content/drive/MyDrive/AD_paper_code/GM\",\n",
        "    \"Thickness\": \"/content/drive/MyDrive/AD_paper_code/Thickness\",\n",
        "    \"WM\": \"/content/drive/MyDrive/AD_paper_code/WM\",\n",
        "    \"CSF\": \"/content/drive/MyDrive/AD_paper_code/CSF\",\n",
        "}\n",
        "\n",
        "regularization_type = 'L2'\n",
        "\n",
        "# Store histories for each dataset\n",
        "histories = {}\n",
        "for title, path in data_dirs.items():\n",
        "    if os.path.exists(path):\n",
        "        histories[title] = train_model(path, regularization_type)\n",
        "    else:\n",
        "        print(f\"Skipping {title}: Path does not exist.\")\n",
        "\n",
        "# Check if we have histories to plot\n",
        "if any(histories.values()):\n",
        "    colors = {\"GM\": \"orange\",\"Thickness\": \"#05f205\",\"WM\": \"blue\", \"CSF\": \"purple\"}\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for title, history in histories.items():\n",
        "        if history and 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "            plt.plot(np.array(history.history['accuracy']) * 100, label=f'{title} Training Accuracy', linestyle='-', color=colors[title])\n",
        "            plt.plot(np.array(history.history['val_accuracy']) * 100, label=f'{title} Validation Accuracy', linestyle='--', color=colors[title])\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('CNN Training vs Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.xticks(np.arange(0, len(history.history['accuracy']), step=1))\n",
        "    plt.yticks(np.arange(0, 101, step=10))\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for title, history in histories.items():\n",
        "        if history and 'loss' in history.history and 'val_loss' in history.history:\n",
        "            plt.plot(history.history['loss'], label=f'{title} Training Loss', linestyle='-', color=colors[title])\n",
        "            plt.plot(history.history['val_loss'], label=f'{title} Validation Loss', linestyle='--', color=colors[title])\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('CNN Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xticks(np.arange(0, len(history.history['loss']), step=1))\n",
        "    plt.yticks(np.arange(0, max(history.history['loss'] + history.history['val_loss']), step=0.5))\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "781HE-hF9_Wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN 2**"
      ],
      "metadata": {
        "id": "np3X6Aue-frz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to load data\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_mapping = {}\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Path {data_dir} does not exist.\")\n",
        "        return None, None, None\n",
        "\n",
        "    class_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])\n",
        "\n",
        "    if not class_folders:\n",
        "        print(f\"No class folders found in {data_dir}\")\n",
        "        return None, None, None\n",
        "\n",
        "    for idx, class_name in enumerate(class_folders):\n",
        "        class_mapping[class_name] = idx\n",
        "\n",
        "    print(f\"Found classes in {data_dir}: {class_mapping}\")\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img = load_img(img_path, target_size=(128, 128))\n",
        "                img_array = img_to_array(img) / 255.0\n",
        "\n",
        "                images.append(img_array)\n",
        "                labels.append(class_mapping[class_name])\n",
        "\n",
        "    return np.array(images), np.array(labels), class_mapping\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Function to train the model\n",
        "def train_model(data_dir, regularization_type=None):\n",
        "    images, labels, class_mapping = load_data(data_dir)\n",
        "\n",
        "    if images is None or labels is None or len(images) == 0:\n",
        "        print(f\"Skipping training for {data_dir} (No data found!)\")\n",
        "        return None, None, None, None, None\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    regularizer = None\n",
        "    if regularization_type == 'L1':\n",
        "        regularizer = regularizers.l1(0.01)\n",
        "    elif regularization_type == 'L2':\n",
        "        regularizer = regularizers.l2(0.01)\n",
        "    elif regularization_type == 'L1_L2':\n",
        "        regularizer = regularizers.l1_l2(l1=0.01, l2=0.01)\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3), kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(len(class_mapping), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Evaluate the model and plot confusion matrix\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "    class_names = [class_name for class_name, idx in sorted(class_mapping.items(), key=lambda x: x[1])]\n",
        "    plot_confusion_matrix(y_test, y_pred, class_names)\n",
        "\n",
        "    return model, X_test, y_test, history, class_mapping\n",
        "\n",
        "# Paths to your dataset\n",
        "data_dir = {\"/content/drive/MyDrive/drive\"}\n",
        "\n",
        "regularization_type = 'L2'\n",
        "\n",
        "# Store models, test data, histories, and class mappings for each dataset\n",
        "models = {}\n",
        "test_data = {}\n",
        "histories = {}\n",
        "class_mappings = {}\n",
        "\n",
        "for title, path in data_dirs.items():\n",
        "    if os.path.exists(path):\n",
        "        model, X_test, y_test, history, class_mapping = train_model(path, regularization_type)\n",
        "        if model is not None:\n",
        "            models[title] = model\n",
        "            test_data[title] = (X_test, y_test)\n",
        "            histories[title] = history\n",
        "            class_mappings[title] = class_mapping\n",
        "    else:\n",
        "        print(f\"Skipping {title}: Path does not exist.\")\n",
        "\n",
        "# Check if we have histories to plot\n",
        "if any(histories.values()):\n",
        "    colors = {\"GM\": \"orange\",\"Thickness\": \"#05f205\",\"WM\": \"blue\", \"CSF\": \"purple\"}\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for title, history in histories.items():\n",
        "        if history and 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "            plt.plot(np.array(history.history['accuracy']) * 100, label=f'{title} Training Accuracy', linestyle='-', color=colors[title])\n",
        "            plt.plot(np.array(history.history['val_accuracy']) * 100, label=f'{title} Validation Accuracy', linestyle='--', color=colors[title])\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('CNN Training vs Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.xticks(np.arange(0, len(history.history['accuracy']), step=1))\n",
        "    plt.yticks(np.arange(0, 101, step=10))\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for title, history in histories.items():\n",
        "        if history and 'loss' in history.history and 'val_loss' in history.history:\n",
        "            plt.plot(history.history['loss'], label=f'{title} Training Loss', linestyle='-', color=colors[title])\n",
        "            plt.plot(history.history['val_loss'], label=f'{title} Validation Loss', linestyle='--', color=colors[title])\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('CNN Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xticks(np.arange(0, len(history.history['loss']), step=1))\n",
        "    plt.yticks(np.arange(0, max(history.history['loss'] + history.history['val_loss']), step=0.5))\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "LIDwZSZ_-rRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**FCN 2**"
      ],
      "metadata": {
        "id": "8lbqN-RI-9kh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras import regularizers\n",
        "from google.colab import drive\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "##################################\n",
        "########## Load Data #############\n",
        "##################################\n",
        "\n",
        "def load_data(data_dir):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_mapping = {}\n",
        "\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Path {data_dir} does not exist.\")\n",
        "        return None, None\n",
        "\n",
        "    class_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])\n",
        "\n",
        "    if not class_folders:\n",
        "        print(f\"No class folders found in {data_dir}\")\n",
        "        return None, None\n",
        "\n",
        "    for idx, class_name in enumerate(class_folders):\n",
        "        class_mapping[class_name] = idx\n",
        "\n",
        "    print(f\"Found classes in {data_dir}: {class_mapping}\")\n",
        "\n",
        "    for class_name in class_folders:\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "\n",
        "        for img_name in os.listdir(class_path):\n",
        "            img_path = os.path.join(class_path, img_name)\n",
        "\n",
        "            if img_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                img = load_img(img_path, target_size=(128, 128))\n",
        "                img_array = img_to_array(img) / 255.0\n",
        "\n",
        "                images.append(img_array)\n",
        "                labels.append(class_mapping[class_name])\n",
        "\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Function to plot confusion matrix\n",
        "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(10, 7))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted Labels')\n",
        "    plt.ylabel('True Labels')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Custom callback (optional for performance reporting)\n",
        "class PerformanceReportCallback(Callback):\n",
        "    def __init__(self, class_mapping, val_data):\n",
        "        super().__init__()\n",
        "        self.class_mapping = class_mapping\n",
        "        self.val_data = val_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        # Custom logic for performance reporting (if needed)\n",
        "        pass\n",
        "\n",
        "##################################\n",
        "########## Training ##############\n",
        "##################################\n",
        "def train_model(data_dir, regularization_type=None):\n",
        "    images, labels = load_data(data_dir)\n",
        "\n",
        "    if images is None or labels is None or len(images) == 0:\n",
        "        print(f\"Skipping training for {data_dir} (No data found!)\")\n",
        "        return None\n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "    regularizer = None\n",
        "    if regularization_type == 'L1':\n",
        "        regularizer = regularizers.l1(0.01)\n",
        "    elif regularization_type == 'L2':\n",
        "        regularizer = regularizers.l2(0.01)\n",
        "    elif regularization_type == 'L1_L2':\n",
        "        regularizer = regularizers.l1_l2(l1=0.01, l2=0.01)\n",
        "\n",
        "    model = tf.keras.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3), kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.Dense(128, activation='relu', kernel_regularizer=regularizer),\n",
        "        layers.Dense(len(set(labels)), activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the model\n",
        "    history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
        "\n",
        "    # Evaluate the model and plot confusion matrix\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "    class_names = [class_name for class_name, idx in sorted({class_name: idx for idx, class_name in enumerate(set(labels))}.items(), key=lambda x: x[1])]\n",
        "    plot_confusion_matrix(y_test, y_pred, class_names)\n",
        "\n",
        "    return history\n",
        "\n",
        "# Paths to your dataset\n",
        "data_dir = {\"/content/drive/MyDrive/drive\"}\n",
        "\n",
        "regularization_type = 'L2'\n",
        "\n",
        "# Store histories for each dataset\n",
        "histories = {}\n",
        "for title, path in data_dirs.items():\n",
        "    if os.path.exists(path):\n",
        "        histories[title] = train_model(path, regularization_type)\n",
        "    else:\n",
        "        print(f\"Skipping {title}: Path does not exist.\")\n",
        "\n",
        "# Check if we have histories to plot\n",
        "if any(histories.values()):\n",
        "    colors = {\"GM\": \"orange\",\"Thickness\": \"#05f205\",\"WM\": \"blue\", \"CSF\": \"purple\"}\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy Plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    for title, history in histories.items():\n",
        "        if history and 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "            plt.plot(np.array(history.history['accuracy']) * 100, label=f'{title} Training Accuracy', linestyle='-', color=colors[title])\n",
        "            plt.plot(np.array(history.history['val_accuracy']) * 100, label=f'{title} Validation Accuracy', linestyle='--', color=colors[title])\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.title('FNN Training vs Validation Accuracy')\n",
        "    plt.legend()\n",
        "    plt.xticks(np.arange(0, len(history.history['accuracy']), step=1))\n",
        "    plt.yticks(np.arange(0, 101, step=10))\n",
        "\n",
        "    # Loss Plot\n",
        "    plt.subplot(1, 2, 2)\n",
        "    for title, history in histories.items():\n",
        "        if history and 'loss' in history.history and 'val_loss' in history.history:\n",
        "            plt.plot(history.history['loss'], label=f'{title} Training Loss', linestyle='-', color=colors[title])\n",
        "            plt.plot(history.history['val_loss'], label=f'{title} Validation Loss', linestyle='--', color=colors[title])\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('FNN Training vs Validation Loss')\n",
        "    plt.legend()\n",
        "    plt.xticks(np.arange(0, len(history.history['loss']), step=1))\n",
        "    plt.yticks(np.arange(0, max(history.history['loss'] + history.history['val_loss']), step=0.5))\n",
        "\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "kuFHYuEg_B-k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}